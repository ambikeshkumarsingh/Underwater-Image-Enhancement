{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageRestorationGAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzi3L5r2gEBN"
      },
      "source": [
        "#Wavelet Decomposition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjHncNt7gAc0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_wav(in_channels, pool=True):\n",
        "    \"\"\"wavelet decomposition using conv2d\"\"\"\n",
        "    harr_wav_L = 1 / np.sqrt(2) * np.ones((1, 2))\n",
        "    harr_wav_H = 1 / np.sqrt(2) * np.ones((1, 2))\n",
        "    harr_wav_H[0, 0] = -1 * harr_wav_H[0, 0]\n",
        "\n",
        "    harr_wav_LL = np.transpose(harr_wav_L) * harr_wav_L\n",
        "    harr_wav_LH = np.transpose(harr_wav_L) * harr_wav_H\n",
        "    harr_wav_HL = np.transpose(harr_wav_H) * harr_wav_L\n",
        "    harr_wav_HH = np.transpose(harr_wav_H) * harr_wav_H\n",
        "\n",
        "    filter_LL = torch.from_numpy(harr_wav_LL).unsqueeze(0)\n",
        "    filter_LH = torch.from_numpy(harr_wav_LH).unsqueeze(0)\n",
        "    filter_HL = torch.from_numpy(harr_wav_HL).unsqueeze(0)\n",
        "    filter_HH = torch.from_numpy(harr_wav_HH).unsqueeze(0)\n",
        "\n",
        "    if pool:\n",
        "        net = nn.Conv2d\n",
        "    else:\n",
        "        net = nn.ConvTranspose2d\n",
        "\n",
        "    LL = net(in_channels, in_channels,\n",
        "             kernel_size=2, stride=2, padding=0, bias=False,\n",
        "             groups=in_channels)\n",
        "    LH = net(in_channels, in_channels,\n",
        "             kernel_size=2, stride=2, padding=0, bias=False,\n",
        "             groups=in_channels)\n",
        "    HL = net(in_channels, in_channels,\n",
        "             kernel_size=2, stride=2, padding=0, bias=False,\n",
        "             groups=in_channels)\n",
        "    HH = net(in_channels, in_channels,\n",
        "             kernel_size=2, stride=2, padding=0, bias=False,\n",
        "             groups=in_channels)\n",
        "\n",
        "    LL.weight.requires_grad = False\n",
        "    LH.weight.requires_grad = False\n",
        "    HL.weight.requires_grad = False\n",
        "    HH.weight.requires_grad = False\n",
        "\n",
        "    LL.weight.data = filter_LL.float().unsqueeze(0).expand(in_channels, -1, -1, -1)\n",
        "    LH.weight.data = filter_LH.float().unsqueeze(0).expand(in_channels, -1, -1, -1)\n",
        "    HL.weight.data = filter_HL.float().unsqueeze(0).expand(in_channels, -1, -1, -1)\n",
        "    HH.weight.data = filter_HH.float().unsqueeze(0).expand(in_channels, -1, -1, -1)\n",
        "\n",
        "    return LL, LH, HL, HH\n",
        "\n",
        "\n",
        "class WavePool(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(WavePool, self).__init__()\n",
        "        self.LL, self.LH, self.HL, self.HH = get_wav(in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.LL(x), self.LH(x), self.HL(x), self.HH(x)\n",
        "\n",
        "\n",
        "class WaveUnpool(nn.Module):\n",
        "    def __init__(self, in_channels, option_unpool='cat5'):\n",
        "        super(WaveUnpool, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.option_unpool = option_unpool\n",
        "        self.LL, self.LH, self.HL, self.HH = get_wav(self.in_channels, pool=False)\n",
        "\n",
        "    def forward(self, LL, LH, HL, HH, original=None):\n",
        "        if self.option_unpool == 'sum':\n",
        "            return self.LL(LL) + self.LH(LH) + self.HL(HL) + self.HH(HH)\n",
        "        elif self.option_unpool == 'cat5' and original is not None:\n",
        "            return torch.cat([self.LL(LL), self.LH(LH), self.HL(HL), self.HH(HH), original], dim=1)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "\n",
        "class WaveEncoder(nn.Module):\n",
        "    def __init__(self, option_unpool):\n",
        "        super(WaveEncoder, self).__init__()\n",
        "        self.option_unpool = option_unpool\n",
        "\n",
        "        self.pad = nn.ReflectionPad2d(1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv0 = nn.Conv2d(3, 3, 1, 1, 0)\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, 3, 1, 0)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, 3, 1, 0)\n",
        "        self.pool1 = WavePool(64)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, 3, 1, 0)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, 3, 1, 0)\n",
        "        self.pool2 = WavePool(128)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, 3, 1, 0)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, 1, 0)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, 1, 0)\n",
        "        self.conv3_4 = nn.Conv2d(256, 256, 3, 1, 0)\n",
        "        self.pool3 = WavePool(256)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, 3, 1, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skips = {}\n",
        "        for level in [1, 2, 3, 4]:\n",
        "            x = self.encode(x, skips, level)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x, skips, level):\n",
        "        assert level in {1, 2, 3, 4}\n",
        "        if self.option_unpool == 'sum':\n",
        "            if level == 1:\n",
        "                out = self.conv0(x)\n",
        "                out = self.relu(self.conv1_1(self.pad(out)))\n",
        "                out = self.relu(self.conv1_2(self.pad(out)))\n",
        "                skips['conv1_2'] = out\n",
        "                LL, LH, HL, HH = self.pool1(out)\n",
        "                skips['pool1'] = [LH, HL, HH]\n",
        "                return LL\n",
        "            elif level == 2:\n",
        "                out = self.relu(self.conv2_1(self.pad(x)))\n",
        "                out = self.relu(self.conv2_2(self.pad(out)))\n",
        "                skips['conv2_2'] = out\n",
        "                LL, LH, HL, HH = self.pool2(out)\n",
        "                skips['pool2'] = [LH, HL, HH]\n",
        "                return LL\n",
        "            elif level == 3:\n",
        "                out = self.relu(self.conv3_1(self.pad(x)))\n",
        "                out = self.relu(self.conv3_2(self.pad(out)))\n",
        "                out = self.relu(self.conv3_3(self.pad(out)))\n",
        "                out = self.relu(self.conv3_4(self.pad(out)))\n",
        "                skips['conv3_4'] = out\n",
        "                LL, LH, HL, HH = self.pool3(out)\n",
        "                skips['pool3'] = [LH, HL, HH]\n",
        "                return LL\n",
        "            else:\n",
        "                return self.relu(self.conv4_1(self.pad(x)))\n",
        "\n",
        "        elif self.option_unpool == 'cat5':\n",
        "            if level == 1:\n",
        "                out = self.conv0(x)\n",
        "                out = self.relu(self.conv1_1(self.pad(out)))\n",
        "                return out\n",
        "\n",
        "            elif level == 2:\n",
        "                out = self.relu(self.conv1_2(self.pad(x)))\n",
        "                skips['conv1_2'] = out\n",
        "                LL, LH, HL, HH = self.pool1(out)\n",
        "                skips['pool1'] = [LH, HL, HH]\n",
        "                out = self.relu(self.conv2_1(self.pad(LL)))\n",
        "                return out\n",
        "\n",
        "            elif level == 3:\n",
        "                out = self.relu(self.conv2_2(self.pad(x)))\n",
        "                skips['conv2_2'] = out\n",
        "                LL, LH, HL, HH = self.pool2(out)\n",
        "                skips['pool2'] = [LH, HL, HH]\n",
        "                out = self.relu(self.conv3_1(self.pad(LL)))\n",
        "                return out\n",
        "\n",
        "            else:\n",
        "                out = self.relu(self.conv3_2(self.pad(x)))\n",
        "                out = self.relu(self.conv3_3(self.pad(out)))\n",
        "                out = self.relu(self.conv3_4(self.pad(out)))\n",
        "                skips['conv3_4'] = out\n",
        "                LL, LH, HL, HH = self.pool3(out)\n",
        "                skips['pool3'] = [LH, HL, HH]\n",
        "                out = self.relu(self.conv4_1(self.pad(LL)))\n",
        "                return out\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "\n",
        "class WaveDecoder(nn.Module):\n",
        "    def __init__(self, option_unpool):\n",
        "        super(WaveDecoder, self).__init__()\n",
        "        self.option_unpool = option_unpool\n",
        "\n",
        "        if option_unpool == 'sum':\n",
        "            multiply_in = 1\n",
        "        elif option_unpool == 'cat5':\n",
        "            multiply_in = 5\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        self.pad = nn.ReflectionPad2d(1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv4_1 = nn.Conv2d(512, 256, 3, 1, 0)\n",
        "\n",
        "        self.recon_block3 = WaveUnpool(256, option_unpool)\n",
        "        if option_unpool == 'sum':\n",
        "            self.conv3_4 = nn.Conv2d(256*multiply_in, 256, 3, 1, 0)\n",
        "        else:\n",
        "            self.conv3_4_2 = nn.Conv2d(256*multiply_in, 256, 3, 1, 0)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, 1, 0)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, 1, 0)\n",
        "        self.conv3_1 = nn.Conv2d(256, 128, 3, 1, 0)\n",
        "\n",
        "        self.recon_block2 = WaveUnpool(128, option_unpool)\n",
        "        if option_unpool == 'sum':\n",
        "            self.conv2_2 = nn.Conv2d(128*multiply_in, 128, 3, 1, 0)\n",
        "        else:\n",
        "            self.conv2_2_2 = nn.Conv2d(128*multiply_in, 128, 3, 1, 0)\n",
        "        self.conv2_1 = nn.Conv2d(128, 64, 3, 1, 0)\n",
        "\n",
        "        self.recon_block1 = WaveUnpool(64, option_unpool)\n",
        "        if option_unpool == 'sum':\n",
        "            self.conv1_2 = nn.Conv2d(64*multiply_in, 64, 3, 1, 0)\n",
        "        else:\n",
        "            self.conv1_2_2 = nn.Conv2d(64*multiply_in, 64, 3, 1, 0)\n",
        "        self.conv1_1 = nn.Conv2d(64, 3, 3, 1, 0)\n",
        "\n",
        "    def forward(self, x, skips):\n",
        "        for level in [4, 3, 2, 1]:\n",
        "            x = self.decode(x, skips, level)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, skips, level):\n",
        "        assert level in {4, 3, 2, 1}\n",
        "        if level == 4:\n",
        "            out = self.relu(self.conv4_1(self.pad(x)))\n",
        "            LH, HL, HH = skips['pool3']\n",
        "            original = skips['conv3_4'] if 'conv3_4' in skips.keys() else None\n",
        "            out = self.recon_block3(out, LH, HL, HH, original)\n",
        "            _conv3_4 = self.conv3_4 if self.option_unpool == 'sum' else self.conv3_4_2\n",
        "            out = self.relu(_conv3_4(self.pad(out)))\n",
        "            out = self.relu(self.conv3_3(self.pad(out)))\n",
        "            return self.relu(self.conv3_2(self.pad(out)))\n",
        "        elif level == 3:\n",
        "            out = self.relu(self.conv3_1(self.pad(x)))\n",
        "            LH, HL, HH = skips['pool2']\n",
        "            original = skips['conv2_2'] if 'conv2_2' in skips.keys() else None\n",
        "            out = self.recon_block2(out, LH, HL, HH, original)\n",
        "            _conv2_2 = self.conv2_2 if self.option_unpool == 'sum' else self.conv2_2_2\n",
        "            return self.relu(_conv2_2(self.pad(out)))\n",
        "        elif level == 2:\n",
        "            out = self.relu(self.conv2_1(self.pad(x)))\n",
        "            LH, HL, HH = skips['pool1']\n",
        "            original = skips['conv1_2'] if 'conv1_2' in skips.keys() else None\n",
        "            out = self.recon_block1(out, LH, HL, HH, original)\n",
        "            _conv1_2 = self.conv1_2 if self.option_unpool == 'sum' else self.conv1_2_2\n",
        "            return self.relu(_conv1_2(self.pad(out)))\n",
        "        else:\n",
        "            return self.conv1_1(self.pad(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oLF1QBkfWx_"
      },
      "source": [
        "# Wavelet Fusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKYipYOXe6RV"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2 \n",
        "import pywt\n",
        "import copy\n",
        "def fuseCoeff(cooef1, cooef2, method):\n",
        "\n",
        "    if (method == 'mean'):\n",
        "        cooef = (cooef1 + cooef2) / 2\n",
        "    elif (method == 'min'):\n",
        "        cooef = np.minimum(cooef1,cooef2)\n",
        "    elif (method == 'max'):\n",
        "        cooef = np.maximum(cooef1,cooef2)\n",
        "    else:\n",
        "        cooef = []\n",
        "\n",
        "    return cooef\n",
        "def main():\n",
        "    img1= cv2.imread(\"/home/rajat/Desktop/test_input1.jpg\")\n",
        "    img2= copy.copy(img1)\n",
        "    b1, g1, r1 =cv2.split(img2)\n",
        "    \n",
        "    hsv = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)\n",
        "    h, s, v =cv2.split(hsv)\n",
        "    a=h.max()\n",
        "    b=h.min()\n",
        "    h-= h.min()\n",
        "    h=h/(a-b)\n",
        "   \n",
        "    h*= 179\n",
        "    \n",
        "    \n",
        "    s-= s.min()\n",
        "    s= s/(s.max()-s.min())\n",
        "    s*=255\n",
        "    v-= v.min()\n",
        "    v= v/(v.max()-v.min())\n",
        "    v*=255\n",
        "    hsv=cv2.merge([h,s,v])\n",
        "    hsv1=hsv.astype(np.float32)\n",
        "    rgb=cv2.cvtColor(hsv1, cv2.COLOR_HSV2RGB)\n",
        "    b, g, r =cv2.split(rgb)\n",
        "    r-= r.min()\n",
        "    r*= 255/(r.max()-r.min())\n",
        "    g-= g.min()\n",
        "    g*= 255/(g.max()-g.min())\n",
        "    b-= b.min()\n",
        "    b*= 255/(b.max()-b.min())\n",
        "    cl1=cv2.merge([b,g,r])\n",
        "    clahe = cv2.createCLAHE()\n",
        "    b2 = clahe.apply(b1)\n",
        "    g2 = clahe.apply(g1)\n",
        "    r2 = clahe.apply(r1)\n",
        "    cl2 =cv2.merge([b2,g2,r2])\n",
        "    \n",
        "    cooef1 = pywt.wavedec2(cl1[:,:], 'db1')\n",
        "    cooef2 = pywt.wavedec2(cl2[:,:], 'db1')\n",
        "    FUSION_METHOD = 'max'\n",
        "    fusedCooef = []\n",
        "    for i in range(len(cooef1)-1):\n",
        "\n",
        "   \n",
        "      if(i == 0):\n",
        "\n",
        "        fusedCooef.append(fuseCoeff(cooef1[0],cooef2[0],FUSION_METHOD))\n",
        "\n",
        "      else:\n",
        "\n",
        "        \n",
        "        c1 = fuseCoeff(cooef1[i][0],cooef2[i][0],FUSION_METHOD)\n",
        "        c2 = fuseCoeff(cooef1[i][1], cooef2[i][1], FUSION_METHOD)\n",
        "        c3 = fuseCoeff(cooef1[i][2], cooef2[i][2], FUSION_METHOD)\n",
        "        \n",
        "\n",
        "        fusedCooef.append((c1,c2,c3))\n",
        "    fusedImage = pywt.waverec2(fusedCooef, 'db1')\n",
        "    fusedImage = np.multiply(np.divide(fusedImage - np.min(fusedImage),(np.max(fusedImage) - np.min(fusedImage))),255)\n",
        "    fusedImage = fusedImage.astype(np.uint8)\n",
        "    cv2.imshow(\"win\",fusedImage)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68qwH6mNfUvD"
      },
      "source": [
        "# GAN architecture extension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq2TQsowgRnF"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import numpy as np\n",
        "# keras libs\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2' # less logs\n",
        "# local libs\n",
        "from utils.plot_utils import save_val_samples\n",
        "from utils.data_utils import dataLoaderUSR, deprocess\n",
        "\n",
        "\n",
        "# training parameters\n",
        "num_epochs = 20\n",
        "batch_size = 2\n",
        "sample_interval = 500 # per step\n",
        "ckpt_interval = 4 # per epoch\n",
        "steps_per_epoch = (data_loader.num_train//batch_size)\n",
        "num_step = num_epochs*steps_per_epoch\n",
        "#####################################################################\n",
        "\n",
        "# choose which model to run\n",
        "model_name = \"srdrm-gan\" # options: [\"srdrm-gan\", \"srgan\", \"esrgan\", \"edsrgan\"]\n",
        "if model_name.lower() == \"srgan\":\n",
        "    from nets.SRGAN import SRGAN_model\n",
        "    gan_model = SRGAN_model(lr_shape, hr_shape, SCALE=4)\n",
        "elif (model_name.lower() ==\"esrgan\"):\n",
        "    from nets.ESRGAN import ESRGAN_model\n",
        "    gan_model = ESRGAN_model(lr_shape, hr_shape, SCALE=4)\n",
        "elif (model_name.lower() ==\"edsrgan\"):\n",
        "    from nets.EDSRGAN import EDSR_model\n",
        "    gan_model = EDSR_model(lr_shape, hr_shape, SCALE=4)\n",
        "else:\n",
        "    print (\"Using default model: SRDRM-GAN\")\n",
        "    from nets.SRDRM import SRDRM_model\n",
        "    gan_model = SRDRM_model(lr_shape, hr_shape, SCALE=4)\n",
        "\n",
        "# checkpoint directory\n",
        "checkpoint_dir = os.path.join(\"checkpoints/\", dataset_name, model_name)\n",
        "if not os.path.exists(checkpoint_dir): os.makedirs(checkpoint_dir)\n",
        "## sample directory\n",
        "samples_dir = os.path.join(\"images/\", dataset_name, model_name)\n",
        "if not os.path.exists(samples_dir): os.makedirs(samples_dir)\n",
        "#####################################################################\n",
        "\n",
        "print (\"\\nGAN training: {0} with {1} data\".format(model_name, dataset_name))\n",
        "## ground-truths for adversarial loss\n",
        "valid = np.ones((batch_size,) + gan_model.disc_patch)\n",
        "fake = np.zeros((batch_size,) + gan_model.disc_patch)\n",
        "step, epoch = 0, 0; start_time = datetime.datetime.now()\n",
        "## training pipeline\n",
        "while (step <= num_step):\n",
        "    for i, (imgs_lr, imgs_hr) in enumerate(data_loader.load_batch(batch_size)):\n",
        "        # train the discriminator\n",
        "        fake_hr = gan_model.generator.predict(imgs_lr)\n",
        "        d_loss_real = gan_model.discriminator.train_on_batch(imgs_hr, valid)\n",
        "        d_loss_fake = gan_model.discriminator.train_on_batch(fake_hr, fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "        # train the generators\n",
        "        image_features = gan_model.vgg.predict(imgs_hr)\n",
        "        if (model_name.lower()==\"srdrm-gan\"): \n",
        "            # custom loss function for SRDRM-GAN\n",
        "            g_loss = gan_model.combined.train_on_batch([imgs_lr, imgs_hr], \n",
        "                                                       [valid, image_features, imgs_hr])\n",
        "        else:\n",
        "            g_loss = gan_model.combined.train_on_batch([imgs_lr, imgs_hr], \n",
        "                                                       [valid, image_features])\n",
        "        # increment step, and show the progress \n",
        "        step += 1; elapsed_time = datetime.datetime.now() - start_time\n",
        "        if (step%10==0):\n",
        "            print (\"[Epoch %d: batch %d/%d] [d_loss: %f] [g_loss: %03f]\" \n",
        "                               %(epoch, i+1, steps_per_epoch, d_loss[0], g_loss[0]))\n",
        "        ## validate and save generated samples at regular intervals \n",
        "        if (step % sample_interval==0):\n",
        "            imgs_lr, imgs_hr = data_loader.load_val_data(batch_size=2)\n",
        "            fake_hr = gan_model.generator.predict(imgs_lr)\n",
        "            gen_imgs = np.concatenate([deprocess(fake_hr), deprocess(imgs_hr)])\n",
        "            save_val_samples(samples_dir, gen_imgs, step)\n",
        "    # increment epoch, save model at regular intervals \n",
        "    epoch += 1\n",
        "    ## save model and weights\n",
        "    if (epoch%ckpt_interval==0):\n",
        "        ckpt_name = os.path.join(checkpoint_dir, (\"model_%d\" %epoch))\n",
        "        with open(ckpt_name+\"_.json\", \"w\") as json_file:\n",
        "            json_file.write(gan_model.generator.to_json())\n",
        "        gan_model.generator.save_weights(ckpt_name+\"_.h5\")\n",
        "        print(\"\\nSaved trained model in {0}\\n\".format(checkpoint_dir))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}